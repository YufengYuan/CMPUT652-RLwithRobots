\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Discussion: Last Lecture}{4-1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Notation}{4-1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Linear Function Approximation}{4-1}{section.3}}
\newlabel{eq:linear_model}{{4.1}{4-1}{Linear Function Approximation}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Exact vs. Sample-based MSE objectives}{4-2}{subsection.3.1}}
\newlabel{eq:MSE_exact}{{4.2}{4-2}{Exact vs. Sample-based MSE objectives}{equation.3.2}{}}
\newlabel{eq:MSE_sample}{{4.3}{4-2}{Exact vs. Sample-based MSE objectives}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Optimization of the Objective function}{4-2}{subsection.3.2}}
\newlabel{der:MSE_exact}{{4.5}{4-2}{Optimization of the Objective function}{equation.3.5}{}}
\newlabel{eq:MSE_exact_solution}{{4.7}{4-3}{Optimization of the Objective function}{equation.3.7}{}}
\newlabel{eq:gradient_descent}{{4.9}{4-3}{Optimization of the Objective function}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Gradient Descent Method and Convergence}{4-3}{subsection.3.3}}
\newlabel{eq:meta_condition}{{4.11}{4-3}{Gradient Descent Method and Convergence}{equation.3.11}{}}
\newlabel{eq:def_spectral}{{4.12}{4-3}{Gradient Descent Method and Convergence}{equation.3.12}{}}
\newlabel{eq:lambda_in_lambda_a}{{4.16}{4-4}{Gradient Descent Method and Convergence}{equation.3.16}{}}
\newlabel{eq:condition}{{4.19}{4-4}{Gradient Descent Method and Convergence}{equation.3.19}{}}
\bibstyle{plain}
\bibdata{reference}
\newlabel{eq:condition2}{{4.21}{4-5}{Gradient Descent Method and Convergence}{equation.3.21}{}}
\newlabel{eq:final_condition}{{4.22}{4-5}{Gradient Descent Method and Convergence}{equation.3.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Non Linear Function Approximation}{4-5}{section.4}}
\newlabel{eq:non_linear_function}{{4.23}{4-5}{Non Linear Function Approximation}{equation.4.23}{}}
\newlabel{eq:g_function}{{4.24}{4-5}{Non Linear Function Approximation}{equation.4.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces A visualization of the said non linear function}}{4-5}{figure.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}SGD and Backpropagation }{4-5}{subsection.4.1}}
\newlabel{eq:backprop1}{{4.25}{4-5}{SGD and Backpropagation}{equation.4.25}{}}
\newlabel{der:weight_optimization_non_linear}{{4.26}{4-5}{SGD and Backpropagation}{equation.4.26}{}}
\newlabel{eq:backprop2}{{4.27}{4-5}{SGD and Backpropagation}{equation.4.27}{}}
